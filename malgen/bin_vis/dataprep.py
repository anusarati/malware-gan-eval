"""Prepares most of an image dataset folder for StyleGAN using distributed computing"""

import json
from vis import visualize
import pandas as pd
import pyarrow.parquet as pq
from pathlib import Path
from malgen.infra.constants import CATEGORIES
import argparse
from math import ceil
from tqdm.contrib.concurrent import thread_map
import torch
import os

from malgen.bin_vis.embedding.embed import embed
from malgen.bin_vis.embedding.color import RGBProjector


def organize_images(idir, size, mode, rank, world_size, base_out, rem=False):
    idir = Path(idir)
    df: pd.DataFrame = pq.read_table(idir / "meta.parquet").to_pandas()

    if rem:
        with open("rem.txt") as f:
            lines = f.readlines()
            paths = map(str.strip, lines)
            paths = map(Path, paths)
            hashes = set(map(lambda p: p.name, paths))
            df = df.query("hash in @hashes")

    outdir = Path(base_out) / str(size) / mode
    outdir.mkdir(parents=True, exist_ok=True)
    for category in CATEGORIES:
        (outdir / category).mkdir(parents=True, exist_ok=True)

    n_rows = df.shape[0]
    n_per_node = ceil(n_rows / world_size)

    df = df.iloc[n_per_node * rank : n_per_node * (rank + 1)]

    if mode == "embed":
        rgbproj = torch.load("rgbproj.pkl")

    def save_image(img, outpath):
        if os.path.isfile(outpath):
            return True
        img.save(outpath)
        return False

    def organize_image(entry):
        filename = entry.hash
        filepath = idir / filename

        if mode == "embed":
            img = embed(filepath=filepath)
            img = rgbproj.pil(img)
        else:
            img = visualize(filepath=filepath, mode=mode)

        if size != "original":
            img = img.resize((size, size))

        filename += ".png"

        category = CATEGORIES[entry.label]
        relpath = Path(category) / filename
        outpath = outdir / relpath
        save_image(img, outpath)

    thread_map(
        organize_image,
        df.itertuples(),
        total=min(n_per_node, n_rows - n_per_node * rank),
    )


def make_dataset_json(idir):
    idir = Path(idir)
    df: pd.DataFrame = pq.read_table(idir / "meta.parquet").to_pandas()

    labels = {}
    for entry in df.itertuples():
        category = CATEGORIES[entry.label]
        labels[os.path.join(category, entry.hash + ".png")] = entry.label
    
    with open('dataset.json','w') as f:
        json.dump(labels, f)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()
    parser.add_argument("-i", "--idir", type=str, required=True)
    vis_parser = subparsers.add_parser("vis")
    vis_parser.add_argument("-world_size", type=int)
    vis_parser.add_argument("-rank", type=int)
    vis_parser.add_argument("-size", required=True)
    vis_parser.add_argument("-mode", type=str)
    vis_parser.add_argument("-o", "--out", type=str, required=True)
    vis_parser.add_argument("-rem", action=argparse.BooleanOptionalAction)
    args = parser.parse_args(dest="which")
    print(args, flush=True)
    if args.which == "vis":
        if args.size != "original":
            args.size = int(args.size)
        organize_images(
            idir=args.idir,
            size=args.size,
            mode=args.mode,
            rank=args.rank,
            world_size=args.world_size,
            base_out=args.out if args.out else ".",
            rem=args.rem,
        )
    else:
        make_dataset_json(idir=args.idir)
