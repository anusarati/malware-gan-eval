"""Calculates color map for malware word embeddings"""

import torch
from torch import nn
import torch.functional as F
from torch.nn.parameter import Parameter
from torchvision.transforms.v2.functional import to_pil_image
import lightning as L
from malgen.bin_vis.embedding.embed import model, get_textinfo


class RGBProjector(L.LightningModule):
    def __init__(self, proj, mean, var):
        super().__init__()
        self.proj = Parameter(proj[:, :3], requires_grad=False)
        self.mean = Parameter(mean[:, None, None], requires_grad=False)
        self.std = Parameter(var.sqrt()[:, None, None], requires_grad=False)
        self.eval()

    @torch.inference_mode()
    def forward(self, img):
        """
        Returns image projected to RGB space normalized to [0, 1]
        img: C x pixel dims
        """
        centered = img - self.mean
        projected = (centered.transpose(-1, 0) @ self.proj).transpose(-1, 0)
        normed_out = 0.5 / self.std * projected
        return 255 / 2 * (normed_out.tanh() + 1)

    def pil(self, img):
        """Returns pillow image of image projected to RGB space"""
        return to_pil_image(self.forward(img))

    def embed_vis(self, filepath):
        # Create image in streaming way
        tokens, side = get_textinfo(filepath)
        buf = torch.empty((3, side, side))
        for i in range(side):
            for j in range(side):
                x = torch.tensor(model[tokens[side * i + j]])
                buf[:, i, j] = self.forward(x.view(-1, 1, 1)).squeeze()
        return to_pil_image(buf)


if __name__ == "__main__":
    import numpy as np
    import fasttext
    from tqdm.contrib.concurrent import thread_map

    model = fasttext.load_model("malbed.bin")
    with open("vocab.txt") as vocab_file:
        vocab = vocab_file.read().split()
    freqs = np.load("tokfreqs.npy")
    freqs = torch.tensor(freqs)
    weights = freqs / freqs.sum()

    vectors = np.empty((len(vocab), model.get_dimension()))
    vectiter = thread_map(model.get_word_vector, vocab)
    for i in range(len(vocab)):
        vectors[i] = vectiter[i]

    vectors = torch.tensor(vectors)

    if torch.cuda.is_available():
        vectors = vectors.to("cuda")
        weights = weights.to("cuda")

    mean = weights.unsqueeze(0) @ vectors
    centered = vectors - mean
    # https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Frequency_weights
    weighted = weights.sqrt().diag() @ centered

    U, S, V = torch.linalg.svd(weighted)
    projected = centered @ V[:, :3]
    var = (freqs.unsqueeze(0) @ projected.square()) / (freqs.sum() - 1)
    mean = mean.flatten()
    var = var.flatten()
    projector = RGBProjector(V, mean, var)
    projector = projector.to("cpu")
    torch.save(projector, "rgbproj.pkl")
