import lightning as L
import os
from pathlib import Path
import pickle
from lightning.pytorch.utilities.types import TRAIN_DATALOADERS
import torch
from torch.utils.data import Dataset, DataLoader, Sampler
import torchvision
from torchvision.transforms import v2
import functools
from math import ceil
import random


def get_image_paths(dir):
    is_image = lambda path: path.suffix in {".pt", ".png", ".jpg", ".jpeg"}
    return list(filter(is_image, dir.iterdir()))


class ImageDataset(Dataset):
    def __init__(self, dir, labels, transform=lambda x: x) -> None:
        super().__init__()
        self.labels = labels
        self.dir = Path(dir)
        self.paths = get_image_paths(dir)
        self.transform = transform

    def __len__(self):
        return len(self.paths)

    def load_image(self, path):
        path = Path(path)
        if path.suffix == ".pt":
            return torch.load(path)
        img = torchvision.io.read_image(path)
        if img.shape[-1] > 512:
            img = v2.functional.resize(
                img,
                (512, 512),
                interpolation=torchvision.transforms.InterpolationMode.BICUBIC,
            )
        elif img.shape[-1] < 64:
            img = v2.functional.resize(
                img,
                (64, 64),
                interpolation=torchvision.transforms.InterpolationMode.BICUBIC,
            )
        return img.float() / 255

    @functools.lru_cache(maxsize=65536)
    def __getitem__(self, index):
        path = self.paths[index]
        label = self.labels[path.name]
        img = self.load_image(path)
        img = self.transform(img)
        return img, label


class BucketSampler(Sampler):
    def __init__(self, data: ImageDataset, batch_size, buckets):
        self.data = data
        self.batch_size = batch_size
        self.buckets = buckets
        self.index = {path: i for i, path in enumerate(data.paths)}
        self.gen_batches()

    def gen_batches(self):
        batches = []
        for paths in self.buckets.values():
            random.shuffle(paths)
            for i in range(ceil(len(paths) / self.batch_size)):
                batches.append(paths[self.batch_size * i : self.batch_size * (i + 1)])
        random.shuffle(batches)
        self.batches = batches

    def __len__(self):
        return ceil(self.batches)

    def __iter__(self):
        for batch in self.batches:
            yield batch
        self.gen_batches()


class ImageDataModule(L.LightningDataModule):
    def __init__(
        self, train_dir, val_dir, num_classes=11, transform=lambda x: x
    ) -> None:
        super().__init__()
        self.batch_size = os.getenv("batch_size") or 1
        self.num_workers = os.getenv("num_workers") or 8
        self.train_dir = Path(train_dir)
        self.val_dir = Path(val_dir)
        self.name = "_".join(self.train_dir.parts[-3:])
        self.num_classes = num_classes

        # we can collect image stats for normalization outside
        self.transform = transform

    def setup(self, stage: str) -> None:

        def get_label_vec(label):
            label_vec = torch.zeros(self.num_classes)
            for class_id in label:
                if class_id < self.num_classes:
                    label_vec[class_id] = 1
            return label_vec

        with open(self.train_dir / "labels.pkl", "rb") as f:
            train_labels = pickle.load(f)

        with open(self.train_dir / "buckets.pkl", "rb") as f:
            train_buckets = pickle.load(f)

        with open(self.val_dir / "buckets.pkl", "rb") as f:
            val_labels = pickle.load(f)

        with open(self.val_dir / "buckets.pkl", "rb") as f:
            val_buckets = pickle.load(f)

        for filename, label in train_labels.items():
            train_labels[filename] = get_label_vec(label)

        for filename, label in val_labels.items():
            val_labels[filename] = get_label_vec(label)

        self.trainset = ImageDataset(
            self.train_dir, train_labels, transform=self.transform
        )
        self.valset = ImageDataset(self.val_dir, val_labels, transform=self.transform)

        self.trainsampler = BucketSampler(self.trainset, self.batch_size, train_buckets)
        self.valsampler = BucketSampler(self.valset, self.batch_size, val_buckets)

    def train_dataloader(self) -> TRAIN_DATALOADERS:
        return DataLoader(
            self.trainset,
            num_workers=self.num_workers,
            batch_sampler=self.trainsampler,
        )

    def val_dataloader(self) -> TRAIN_DATALOADERS:
        return DataLoader(
            self.valset, num_workers=self.num_workers, batch_sampler=self.valsampler
        )
