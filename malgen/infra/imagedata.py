import lightning as L
import os
from pathlib import Path
import pickle
from lightning.pytorch.utilities.types import TRAIN_DATALOADERS
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision
from torchvision.transforms import v2
import functools
from collections.abc import Iterable


def get_image_paths(dir):
    is_image = lambda path: path.ext in {".pt", ".png", ".jpg", ".jpeg"}
    return list(filter(is_image, dir.iterdir()))


class ImageDataset(Dataset):
    def __init__(self, dir, labels, transform=lambda x: x) -> None:
        super().__init__()
        self.labels = labels
        self.dir = Path(dir)
        self.paths = get_image_paths(dir)
        self.transform = transform

    def __len__(self):
        return len(self.paths)

    def load_image(self, path):
        path = Path(path)
        if path.ext == ".pt":
            return torch.load(path)
        img = torchvision.io.read_image(path)
        return img.float() / 255

    @functools.lru_cache(maxsize=65536)
    def __getitem__(self, index):
        path = self.paths[index]
        label = self.labels[path]
        img = self.load_image(path)
        img = self.transform(img)
        return img, label


class ImageDataModule(L.LightningDataModule):
    def __init__(
        self, train_dir, val_dir, num_classes=11, transform=lambda x: x
    ) -> None:
        super().__init__()
        self.batch_size = os.getenv("batch_size") or None
        self.num_workers = os.getenv("num_workers") or 8
        self.train_dir = Path(train_dir)
        self.val_dir = Path(val_dir)
        self.name = train_dir.name
        self.num_classes = num_classes

        # we can collect image stats for normalization outside
        self.transform = transform

    def setup(self, stage: str) -> None:

        def get_label_vec(filename):
            label_vec = torch.zeros(self.num_classes)
            for class_id in self.labels[filename]:
                if class_id < self.num_classes:
                    label_vec[class_id] = 1
            return label_vec

        with open(self.train_dir / "labels.pkl", "rb") as f:
            train_labels = pickle.load(f)

        with open(self.val_dir / "labels.pkl", "rb") as f:
            val_labels = pickle.load(f)

        for filename, label in train_labels:
            train_labels[filename] = get_label_vec(filename, label)

        for filename, label in val_labels:
            val_labels[filename] = get_label_vec(filename, label)

        self.trainset = ImageDataset(
            self.train_dir, train_labels, transform=self.transform
        )
        self.valset = ImageDataset(self.val_dir, val_labels, transform=self.transform)

    def train_dataloader(self) -> TRAIN_DATALOADERS:
        return DataLoader(
            self.trainset, batch_size=self.batch_size, num_workers=self.num_workers
        )

    def val_dataloader(self) -> TRAIN_DATALOADERS:
        return DataLoader(
            self.valset, batch_size=self.batch_size, num_workers=self.num_workers
        )
