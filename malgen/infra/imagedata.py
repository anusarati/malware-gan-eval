import lightning as L
import os
from pathlib import Path
import pickle
from lightning.pytorch.utilities.types import TRAIN_DATALOADERS
import torch
from torch.utils.data import Dataset, DataLoader, Sampler
import torchvision
from torchvision.transforms import v2
import functools
from math import ceil
import random


def get_image_paths(dir):
    is_image = lambda path: Path(path).suffix in {".pt", ".png", ".jpg", ".jpeg"}
    paths = [
        Path(dirpath) / filename
        for dirpath, _, filenames in os.walk(dir)
        for filename in filenames
        if is_image(filename)
    ]
    return paths


class ImageDataset(Dataset):
    def __init__(self, dir, labels, transform=lambda x: x) -> None:
        super().__init__()
        self.labels = labels
        self.dir = Path(dir)
        self.paths = get_image_paths(dir)
        self.transform = transform

    def __len__(self):
        return len(self.paths)

    def load_image(self, path):
        path = Path(path)
        if path.suffix == ".pt":
            return torch.load(path)
        img = torchvision.io.read_image(path)
        if img.shape[-1] > 512:
            img = v2.functional.resize(
                img,
                (512, 512),
                interpolation=torchvision.transforms.InterpolationMode.BICUBIC,
            )
        elif img.shape[-1] < 64:
            img = v2.functional.resize(
                img,
                (64, 64),
                interpolation=torchvision.transforms.InterpolationMode.BICUBIC,
            )
        return img.float() / 255

    @functools.lru_cache(maxsize=65536)
    def __getitem__(self, index):
        path = self.paths[index]
        img = self.load_image(path)
        img = self.transform(img)
        if self.labels:
            label = self.labels[path.name]
            return img, label
        return img


class BucketSampler(Sampler):
    def __init__(self, data: ImageDataset, batch_size, buckets):
        self.data = data
        self.batch_size = batch_size
        self.buckets = buckets
        self.index = {path: i for i, path in enumerate(data.paths)}
        self.gen_batches()

    def gen_batches(self):
        batches = []
        for paths in self.buckets.values():
            random.shuffle(paths)
            for i in range(ceil(len(paths) / self.batch_size)):
                batches.append(paths[self.batch_size * i : self.batch_size * (i + 1)])
        random.shuffle(batches)
        self.batches = batches

    def __len__(self):
        return ceil(self.batches)

    def __iter__(self):
        for batch in self.batches:
            yield batch
        self.gen_batches()


class ImageDataModule(L.LightningDataModule):
    def __init__(
        self,
        batch_size=16,
        num_workers=8,
        train_dir=None,
        val_dir=None,
        num_classes=11,
        transform=lambda x: x,
        label=True,
        bucket=True,
    ) -> None:
        super().__init__()
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.train_dir = Path(train_dir) if train_dir else None
        self.val_dir = Path(val_dir) if val_dir else None
        self.name = "_".join(Path(train_dir or val_dir).parts[-3:])
        self.num_classes = num_classes

        # we can collect image stats for normalization outside
        self.transform = transform
        self.label = label
        self.bucket = bucket

    def setup(self, stage: str) -> None:
        def get_label_vec(label):
            label_vec = torch.zeros(self.num_classes)
            for class_id in label:
                if class_id < self.num_classes:
                    label_vec[class_id] = 1
            return label_vec

        def setup_part(idir):
            if not idir:
                return (None,) * 2
            if self.label:
                with open(idir / "labels.pkl", "rb") as f:
                    labels = pickle.load(f)
                for filename, label in labels.items():
                    labels[filename] = get_label_vec(label)
            else:
                labels = None
            dataset = ImageDataset(idir, labels, transform=self.transform)
            if self.bucket:
                with open(idir / "buckets.pkl", "rb") as f:
                    buckets = pickle.load(f)
                sampler = BucketSampler(dataset, self.batch_size, buckets)
            return dataset, sampler

        self.trainset, self.train_sampler = setup_part(self.train_dir)
        self.valset, self.val_sampler = setup_part(self.val_dir)

    def train_dataloader(self) -> TRAIN_DATALOADERS:
        if self.bucket:
            return DataLoader(
                self.trainset,
                num_workers=self.num_workers,
                batch_sampler=self.trainsampler,
            )
        return DataLoader(
            self.trainset, num_workers=self.num_workers, batch_size=self.batch_size
        )

    def val_dataloader(self) -> TRAIN_DATALOADERS:
        if self.bucket:
            return DataLoader(
                self.valset,
                num_workers=self.num_workers,
                batch_sampler=self.valsampler,
            )
        return DataLoader(
            self.valset, num_workers=self.num_workers, batch_size=self.batch_size
        )
