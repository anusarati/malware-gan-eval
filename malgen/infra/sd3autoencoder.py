from ldm.models.autoencoder import AutoencoderKL
import lightning as L
from lightning.pytorch.callbacks import ModelCheckpoint
from malgen.infra.imagedata import ImageDataModule
import argparse

# https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py
# https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/convert_from_ckpt.py
# https://huggingface.co/docs/diffusers/en/api/models/autoencoderkl#loading-from-the-original-format
# https://github.com/huggingface/diffusers/blob/main/scripts/convert_diffusers_to_original_stable_diffusion.py


def get_model(lpips_kwargs, channels):
    lossconfig = {
        "target": "ldm.modules.losses.LPIPSWithDiscriminator",
        "params": {
            "disc_start": 50001,
            "kl_weight": 0.000001,
            "disc_weight": 0.5,
            "lpips_kwargs": lpips_kwargs,
        },
    }
    ddconfig = {
        "double_z": True,
        "z_channels": 16,
        "resolution": 256,
        "in_channels": channels,
        "out_ch": channels,
        "ch": 128,
        "ch_mult": [1, 2, 4, 4],
        "num_res_blocks": 2,
        "attn_resolutions": [16],
        "dropout": 0.0,
    }
    embed_dim = 16
    model = AutoencoderKL(ddconfig, lossconfig, embed_dim)
    return model


def train(model, train_dir, val_dir):
    trainer = L.Trainer(
        devices=-1,
        precision="bf16-mixed",
        gradient_clip_val=1,
        max_epochs=10,
        callbacks=ModelCheckpoint(monitor="val/rec_loss", save_top_k=2),
    )
    datamod = ImageDataModule(train_dir, val_dir, label=False)
    trainer.fit(model, datamodule=datamod)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-tr", "--train_dir", type=str)
    parser.add_argument("-va", "--val_dir", type=str)
    parser.add_argument("-ch", "--channels", type=int)
    parser.add_argument(
        "-ck", "--checkpoint", type=str, help="Checkpoint path for feature extractor"
    )
    parser.add_argument(
        "-sm", "--scale_mean", nargs="+", help="Mean of image channels", type=int
    )
    parser.add_argument(
        "-sd",
        "--scale_stdev",
        nargs="+",
        help="Standard deviations of image channels",
        type=int,
    )
    args = parser.parse_args()
    print(args)
    lpips_kwargs = {
        "custom_checkpoint": args.checkpoint,
        "scale_params": [args.scale_mean, args.scale_stdev],
    }
    model = get_model(lpips_kwargs, args.channels)
    train(model, args.train_dir, args.val_dir)
