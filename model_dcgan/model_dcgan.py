import torch
from torch import optim, nn
from torch.utils.data import DataLoader

import torchvision
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torchvision.datasets import MNIST


import math
import matplotlib.pyplot as plt
import numpy as np

import lightning as L
from lightning.pytorch.callbacks.early_stopping import EarlyStopping

import os

class ModelDCGAN_DataModule(L.LightningDataModule):
    """
    The DataModule class for ModelDCGAN. Sets up the dataset and dataloader.

    Attributes
    ----------
    data_dir : path object
        The path to the directory containing the image data.
    batch_size : int
        The size of each batch the dataloader will serve.
    num_workers : int
        The number of workers used by the dataloader.
    """

    def __init__(self, data_dir, img_size, batch_size=128, num_workers=2):
        """
        Parameters
        ----------
        data_dir : path object
            The path to the directory containing the image data.
        batch_size : int
            The size of each batch the dataloader will serve.
        num_workers : int
            The number of workers used by the dataloader.
        """
        super().__init__()
        self.data_dir = data_dir
        self.img_size = img_size
        self.batch_size = batch_size
        self.prepare_data_per_node = True
        self.num_workers = num_workers

        self.img_resize = 2**(math.ceil(math.log(img_size, 2)))
        self.transform = transforms.Compose([
                                    transforms.Resize(self.img_resize),
                                    transforms.ToTensor(),
                                    transforms.Normalize((0.5,), (0.5,))
                                ])

    def prepare_data(self):
        """
        Downloads training data from CIFAR10 if not downloaded already.
        """
        MNIST(self.data_dir, train=True, download=True)

    def setup(self, stage=None):
        """
        Sets up the training data from CIFAR10.
        """
        if stage == "fit" or stage is None:
            self.data_train = MNIST(self.data_dir, train=True, transform=self.transform)

    def train_dataloader(self):
        """
        Creates the DataLoader for ModelDCGAN.
        """
        dataloader = DataLoader(self.data_train, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)
        return dataloader

#Generator class for a DCGAN
class Generator(nn.Module):
    """
    A class for the Generator of the ModelDCGAN.

    Attributes
    ----------
    num_channels : int
        The number of image channels being used.
    img_size : int
        The side length of an image, given the image is a square.
    latent_dim : int
        The size of the latent vector given to the Generator.
    """

    def __init__(self, num_channels, img_size, num_classes, embed_size, latent_dim):
        """
        Parameters
        ----------
        num_channels : int
            The number of image channels being used.
        img_size : int
            The side length of an image, given the image is a square.
        latent_dim : int
            The size of the latent vector given to the Generator.
        """
        super().__init__()
        self.num_channels = num_channels
        self.img_size = img_size
        self.num_classes = num_classes
        self.latent_dim = latent_dim
        self.img_shape = (num_channels, img_size, img_size)

        layers = []
        n = int(math.log(img_size, 2) - 3)

        layers.append(nn.ConvTranspose2d(latent_dim + embed_size, img_size * 2**n, 4, 1, 0, bias=False))
        layers.append(nn.BatchNorm2d(img_size * 2**n))
        layers.append(nn.ReLU(True))
        for k in reversed(range(n)):
            layers.append(nn.ConvTranspose2d(img_size * 2**(k+1), img_size * 2**k, 4, 2, 1, bias=False))
            layers.append(nn.BatchNorm2d(img_size * 2**k))
            layers.append(nn.ReLU(True))
        layers.append(nn.ConvTranspose2d(img_size, num_channels, 4, 2, 1, bias=False))
        layers.append(nn.Tanh())

        self.model = nn.Sequential(*layers)

        self.embed = nn.Embedding(num_classes, embed_size)

    
    def forward(self, noise, class_labels):
        """
        Defines a forward pass in the network of the Generator.

        Parameters
        ----------
        noise : tensor
            a tensor filled with random numbers, representing the latent vector to input.
        """
        embedded_labels = self.embed(class_labels)
        #print("Embedded labels: {}".format(embedded_labels.shape))
        input = torch.cat([noise, embedded_labels], -1).unsqueeze(2).unsqueeze(3)
        #print("Input: {}".format(input))
        output = self.model(input)
        return output.view(output.size(0), *self.img_shape)
    
#Discriminator class for a DCGAN:
class Discriminator(nn.Module):
    def __init__(self, num_channels, img_size, num_classes, leaky_slope):
        """
        A class for the Discriminator of the ModelDCGAN.

        Attributes
        ----------
        num_channels : int
            The number of image channels being used.
        img_size : int
            The side length of an image, given the image is a square.
        leaky_slope : float
            The slope used for the LeakyReLU activation function.
        """
        super().__init__()
        self.img_size = img_size
        img_shape = (num_channels, img_size, img_size)

        layers = []
        n = int(math.log(img_size, 2) - 3)
        ndf = int(img_size)

        layers.append(nn.Conv2d(num_classes + int(np.prod(img_shape)), ndf, 4, 2, 1, bias=False))
        layers.append(nn.LeakyReLU(leaky_slope, True))
        for k in range(n):
            layers.append(nn.Conv2d(ndf * 2**k, ndf * 2**(k+1), 4, 2, 1, bias=False))
            layers.append(nn.BatchNorm2d(ndf * 2**(k+1)))
            layers.append(nn.LeakyReLU(leaky_slope, True))
        layers.append(nn.Conv2d(ndf * 2**n, 1, 4, 1, 0, bias=False))
        layers.append(nn.Sigmoid())

        self.model = nn.Sequential(*layers)

        self.embed = nn.Embedding(num_classes, num_classes)

    def forward(self, images, class_labels):
        """
        Defines a forward pass in the network of the Discriminator.

        Parameters
        ----------
        images : tensor
            the data for the images the Discriminator must classify.
        """
        embedded_labels = self.embed(class_labels)
        #print("images: {}".format(images.shape))
        #print("class_labels: {}".format(class_labels.shape))
        #print("embedded_labels: {}".format(embedded_labels.shape))
        x = images.view(images.size(0), -1)
        #print("x: {}".format(x.shape))
        x_input = torch.cat([x, embedded_labels], -1).unsqueeze(2).unsqueeze(3)
        #print("x_input: {}".format(x_input.shape))
        output = self.model(x_input)
        return output
    
class ModelDCGAN(L.LightningModule):
    
    def __init__(self, num_channels, img_size, num_classes, dvc="cuda", embed_size=100, latent_dim=100, leaky_slope=0.2, lr=0.0002, beta1=0.5, beta2=0.999, batch_size=128):
        super().__init__()
        self.save_hyperparameters()
        self.img_resize = 2**(math.ceil(math.log(img_size, 2)))
        self.epoch_number = 0

        def weights_init(m):
            classname = m.__class__.__name__
            if classname.find('Conv') != -1:
                nn.init.normal_(m.weight.data, 0.0, 0.02)
            elif classname.find('BatchNorm') != -1:
                nn.init.normal_(m.weight.data, 1.0, 0.02)
                nn.init.constant_(m.bias.data, 0)

        self.generator = Generator(num_channels, self.img_resize, num_classes, embed_size, latent_dim)
        self.discriminator = Discriminator(num_channels, self.img_resize, num_classes, leaky_slope)

        self.generator.apply(weights_init)
        self.discriminator.apply(weights_init)
        
        print(self.generator)
        print("=================================")
        print(self.discriminator)

        self.dvc = dvc

        #self.control_noise = torch.randn(8 * num_classes, latent_dim, 1, 1).to(dvc)
        #self.control_labels = torch.flatten(torch.tensor([[i] * 8 for i in range(num_classes)])).to(dvc)
        self.control_noise = torch.randn(8 * num_classes, latent_dim).to(dvc)
        self.control_labels = torch.LongTensor(np.array([num for _ in range(8) for num in range(10)])).to(dvc)

        self.automatic_optimization = False

    def forward(self, noise, class_labels):
        return self.generator(noise, class_labels)
    
    def loss(self, expected_rf_labels, actual_rf_labels):
        loss_function = nn.BCELoss()
        return loss_function(expected_rf_labels, actual_rf_labels)
    
    def training_step(self, batch, batch_idx):
        latent_dim = self.hparams.latent_dim
        
        real_imgs, class_labels = batch
        
        print("Real Imgs: {}".format(real_imgs.shape))
        print("Class labels: {}".format(class_labels.shape))
        
        real_imgs = real_imgs.to(self.dvc)
        class_labels = class_labels.to(self.dvc)
        noise = torch.randn(real_imgs.shape[0], latent_dim).to(self.dvc)
        #print("Noise: {}".format(noise.shape))
        opt_g, opt_d = self.optimizers()

        #Train generator
        opt_g.zero_grad()
        generated_imgs = self(noise, class_labels) #SEND TO G!
        expected_rf_labels = self.discriminator(generated_imgs, class_labels).view(-1) #SEND TO D!
        g_loss = self.loss(expected_rf_labels, torch.ones(real_imgs.size(0)).to(self.dvc))
        self.manual_backward(g_loss)
        opt_g.step()
        self.log("g_loss", g_loss, prog_bar=True)

        #Train discriminator
        opt_d.zero_grad()
        realset_expected_rf_labels = self.discriminator(real_imgs, class_labels).view(-1) #SEND TO D!
        realset_loss = self.loss(realset_expected_rf_labels, torch.ones(real_imgs.size(0)).to(self.dvc))
        fakeset_expected_rf_labels = self.discriminator(generated_imgs.detach(), class_labels).view(-1) #SEND TO D!
        fakeset_loss = self.loss(fakeset_expected_rf_labels, torch.zeros(real_imgs.size(0)).to(self.dvc))
        d_loss = (realset_loss + fakeset_loss) / 2
        self.manual_backward(d_loss)
        opt_d.step()
        self.log("d_loss", d_loss, prog_bar=True)

        return g_loss + d_loss
    
    def on_train_epoch_end(self):
        num_classes = self.hparams.num_classes
        latent_dim = self.hparams.latent_dim
        img_size = self.hparams.img_size

        if self.epoch_number % 2 == 0:
            generated_control = self(self.control_noise, self.control_labels)
            #print("Generated Control: {}".format(generated_control.shape))
            fig = plt.figure(figsize=(10,10))
            plt.axis("off")
            plt.title("ModelDCGAN Images After {} Epochs".format(self.epoch_number))
            grid = vutils.make_grid(generated_control, padding=2, normalize=True, nrow=10)
            plt.imshow(np.transpose(grid, (1, 2, 0)))
            plt.savefig("dcgan_{:02d}.png".format(self.epoch_number))
            plt.close(fig)
        self.epoch_number += 1
    
    def configure_optimizers(self):
        lr = self.hparams.lr
        beta1 = self.hparams.beta1
        beta2 = self.hparams.beta2
        opt_g = optim.Adam(self.generator.parameters(), lr=lr, betas=(beta1, beta2))
        opt_d = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(beta1, beta2))
        return [opt_g, opt_d], []


class ModelDCGAN_EarlyStopping(EarlyStopping):

    def on_validation_end(self, trainer, l_module):
        # override this to disable early stopping at the end of val loop
        pass

    def on_train_end(self, trainer, l_module):
        # instead, do it at the end of training loop
        self._run_early_stopping_check(trainer)
