from collections import OrderedDict
import torch
from torch import nn, optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import lightning as L

#DataModule class:
class ModelDCGAN_DataModule(L.LightningDataModule):
    #Constructor:
    def __init__(self, img_folder, batch_size=128, num_workers=2):
        self.img_folder = img_folder
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.transform = transforms.Compose([
                                    transforms.ToTensor(),
                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                                ])
        self.dl_dict = {'batch_size': self.batch_size, 'num_workers': self.num_workers}

    #Get the data:
    def setup(self):
        self.dataset = dset.ImageFolder(root=self.img_folder, transform=self.transform)

    #Data Loader:
    def train_dataloader(self, batch_size, num_workers):
        dataloader = torch.utils.data.DataLoader(self.dataset, **self.dl_dict)
        return dataloader
    

#Generator class for a DCGAN:
class Generator(nn.Module):
    def __init__(self, num_channels, img_size, latent_dim):
        super().__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, img_size * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(img_size * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(img_size * 8, img_size * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(img_size * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(img_size * 4, img_size * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(img_size * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(img_size * 2, img_size, 4, 2, 1, bias=False),
            nn.BatchNorm2d(img_size),
            nn.ReLU(True),
            nn.ConvTranspose2d(img_size, num_channels, 4, 2, 1, bias=False),
            nn.Tanh()
        )
    
    def forward(self, input):
        return self.model(input)
    
#Discriminator class for a DCGAN:
class Discriminator(nn.Module):
    def __init__(self, num_channels, img_size, leaky_slope=0.2):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(num_channels, img_size, 4, 2, 1, bias=False),
            nn.LeakyReLU(leaky_slope, True),
            nn.Conv2d(img_size, img_size * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(img_size * 2),
            nn.LeakyReLU(leaky_slope, True),
            nn.Conv2d(img_size * 2, img_size * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(img_size * 4),
            nn.LeakyReLU(leaky_slope, True),
            nn.Conv2d(img_size * 4, img_size * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(img_size * 8),
            nn.LeakyReLU(leaky_slope, True),
            nn.Conv2d(img_size * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.model(input)
    
class ModelDCGAN(L.LightningModule):
    def __init__(self, latent_dim=100, lr=0.0002, beta1=0.5, beta2=0.999, batch_size=128):
        super().__init__()
        self.save_hyperparameters()

        #Create a generator
        self.generator = Generator(latent_dim=self.hparams.latent_dim)

        #Create a discriminator
        self.discriminator = Discriminator()

    def forward(self, input):
        return self.generator(input)
    
    def loss(self, expected_labels, actual_labels):
        loss_function = nn.BCELoss()
        return loss_function(expected_labels, actual_labels)
    
    #Training step, returns losses and progress bar info
    def training_step(self, batch, batch_idx, optimizer_idx):
        real_imgs,_ = batch
        noise = torch.randn(real_imgs.shape[0], self.hparams.latent_dim)

        #Train generator
        if optimizer_idx == 0:
            self.generated_imgs = self(noise)
            expected_labels = self.discriminator(self.generated_imgs)
            g_loss = self.loss(expected_labels, torch.ones(real_imgs.size(0), 1))
            tqdm_dict = {"g_loss": g_loss}
            output = OrderedDict({"loss": g_loss, "progress_bar": tqdm_dict, "log": tqdm_dict})
            return output
        
        #Train discriminator
        if optimizer_idx == 1:
            realset_expected_labels = self.discriminator(real_imgs)
            realset_loss = self.loss(realset_expected_labels, torch.ones(real_imgs.size(0), 1))

            fakeset_expected_labels = self.discriminator(self(noise).detach())
            fakeset_loss = self.loss(fakeset_expected_labels, torch.zeros(real_imgs.size(0), 1))

            d_loss = (realset_loss + fakeset_loss) / 2
            tqdm_dict = {"d_loss": d_loss}
            output = OrderedDict({"loss": d_loss, "progress_bar": tqdm_dict, "log": tqdm_dict})
            return output
        
    #Optimizers
    def configure_optimizers(self):
        lr = self.hparams.lr
        beta1 = self.hparams.beta1
        beta2 = self.hparams.beta2

        opt_g = optim.Adam(self.generator.parameters(), lr=lr, betas=(beta1, beta2))
        opt_d = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(beta1, beta2))
        return [opt_g, opt_d], [] #returns list of optimizers and empty list of schedulers (which we don't really care about)
    

#   To create this model and train it:
#
#   trainer = L.Trainer(max_epochs=100)
#   model = ModelDCGAN()
#   data_module = ModelDCGAN_DataModule()
#   trainer.fit(model, data_module)




    


