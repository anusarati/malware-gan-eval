"""Calculates color map for malware word embeddings"""

import torch
from torch import nn
import torch.functional as F
from torch.nn.parameter import Parameter
from torchvision.transforms.v2.functional import to_pil_image
import lightning as L


class RGBProjector(L.LightningModule):
    def __init__(self, proj, mean, low, high):
        super().__init__()
        self.proj = Parameter(proj[:, :3], requires_grad=False)
        self.mean = Parameter(mean[:, None, None], requires_grad=False)
        self.low = Parameter(low[:, None, None], requires_grad=False)
        self.high = Parameter(high[:, None, None], requires_grad=False)
        self.eval()

    @torch.inference_mode()
    def forward(self, img):
        """Returns image projected to RGB space normalized to [0, 1]"""
        normed_inp = img.tanh() - self.mean
        projected = (normed_inp.transpose(-1, 0) @ self.proj).transpose(-1, 0)
        scale_factor = (self.high - self.low).reciprocal()
        normed_out = scale_factor * (projected - self.low)
        # hopefully shouldn't lie too far outside word embeddings
        return normed_out.clamp(0, 1)

    def pil(self, img):
        """Returns pillow image of image projected to RGB space"""
        return to_pil_image(self.forward(img))


if __name__ == "__main__":
    import numpy as np
    import fasttext
    from tqdm.contrib.concurrent import thread_map

    model = fasttext.load_model("malbed.bin")
    with open("vocab.txt") as vocab_file:
        vocab = vocab_file.read().split()
        vectors = np.empty((len(vocab), 64))
        vectiter = thread_map(model.get_word_vector, vocab)
        for i in range(len(vocab)):
            vectors[i] = vectiter[i]
        vectors = torch.tensor(vectors)
        if torch.cuda.is_available():
            vectors = vectors.to("cuda")
        vectors = vectors.tanh()
        mean = vectors.mean(0)

        vectors = vectors - mean
        print("var:", vectors.var(0))
        U, S, V = torch.linalg.svd(vectors)
        projected = vectors @ V[:, :3]
        min_comp = projected.min(0).values
        max_comp = projected.max(0).values
        projector = RGBProjector(V, mean, min_comp, max_comp)
        projector = projector.to("cpu")
        torch.save(projector, "rgbproj.pkl")
