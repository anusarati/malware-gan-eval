"""Train model to generate embeddings for byte sequences"""

import torch
from torch import optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.parameter import Parameter
from transformers import AutoModelForMaskedLM, AutoConfig
import lightning as L
from lightning.pytorch.callbacks import ModelCheckpoint
import pandas as pd
from mlm_pytorch import MLM
from pathlib import Path
import random
from math import sqrt
import os

# in a 512x512 image, each pixel needs to encode 38 bytes to represent a 10 MB binary


class Embedder(L.LightningModule):
    def __init__(self, model, model_name="roberta"):
        super().__init__()
        if isinstance(model, Embedder):
            self.model = model.model
            self.mlm_trainer = model.mlm_trainer
        else:
            self.model = model
            self.mlm_trainer = MLM(
                transformer=lambda x: model(x).logits,
                mask_token_id=256,
                pad_token_id=257,
                mask_prob=0.15,
                replace_prob=0.90,
                mask_ignore_token_ids=[],
            )
        self.save_hyperparameters()
        # self.encoder = self.model.__getattr__(model_name)

    def training_step(self, batch, batch_idx):
        loss = self.mlm_trainer(batch[0])
        self.log("loss", loss, prog_bar=True)
        return loss

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters())
        return optimizer

    def embed(self, path, seq_len):
        """
        Returns embeddings for each consecutive seq_len byte sequence in a file
        truncated to the nearest square multiple of seq_len bytes
        """
        with open(path, "rb", buffering=0) as f:
            size = os.path.getsize(path)
            n = int(sqrt(size / seq_len)) ** 2
            bins = (f.read(seq_len) for _ in range(n))
            inputs = (list(torch.tensor(bin)) for bin in bins)
            embeds = tuple(self.encoder(input).mean() for input in inputs)
            return torch.stack(embeds)

    def embed_image(self, path):
        """Returns an image of embeddings for a file"""
        emb = self.embed(path)
        n = emb.shape[0]
        features = emb.shape[1]
        side = int(sqrt(n))
        # convert features to channels
        emb = emb.transpose(0, 1).reshape(1, features, side, side)
        return emb


class BinaryDataset(Dataset):
    def __init__(self, dir, seq_len):
        super().__init__()
        self.paths = list(Path(dir).iterdir())
        self.seq_len = seq_len

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        """Returns up to 128 random sequences of seq_len bytes from a file"""
        path = self.paths[idx]
        with open(path, "rb", buffering=0) as f:
            bin = f.readall()
            sequences = tuple(
                torch.tensor(list(bin[p : p + self.seq_len]))
                for p in [random.randrange(len(bin) - self.seq_len) for _ in range(128)]
            )
            return torch.stack(sequences)


meta = pd.read_pickle("100k.pkl")


def surgery(model, model_name, vocab_size):
    """Shrinks the number of input/output tokens of the model"""
    special = model.__getattr__(model_name)
    word_embeddings = special.embeddings.word_embeddings
    word_embeddings.weight = Parameter(word_embeddings.weight[:vocab_size, :])
    word_embeddings.num_embeddings = vocab_size
    decoder = model.lm_head.decoder
    decoder.weight = Parameter(decoder.weight[:vocab_size, :])
    decoder.bias = Parameter(decoder.bias[:vocab_size])
    decoder.out_features = vocab_size


def get_fresh_pretrained():
    model = AutoModelForMaskedLM.from_pretrained("distilbert/distilroberta-base")
    surgery(model, "roberta", 258)
    return Embedder(model, "roberta")


embedder = Embedder.load_from_checkpoint(
    "lightning_logs/version_350607/checkpoints/epoch=0-step=105652.ckpt",
    model=get_fresh_pretrained(),
)

print(embedder.model.lm_head.decoder.bias)


def train(seq_len):
    dataset = BinaryDataset("bins/decompressed", seq_len)
    dataloader = DataLoader(dataset, num_workers=64, prefetch_factor=10)

    EPOCHS = 2
    torch.set_float32_matmul_precision("medium")

    trainer = L.Trainer(
        max_epochs=EPOCHS,
        callbacks=ModelCheckpoint(
            save_on_train_epoch_end=True, save_last=True, every_n_train_steps=10000
        ),
    )
    trainer.fit(model=embedder, train_dataloaders=dataloader)


train(512)


class ChannelReducer:
    """Reduces number of channels using PCA"""

    def __init__(self, data, n):
        _, _, self.V = torch.pca_lowrank(data, n)

    def reduce(self, img):
        return
